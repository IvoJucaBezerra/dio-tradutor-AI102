{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzDik7qFL4zR",
        "outputId": "ca082a61-0663-4a24-81bc-178075df6599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai) (1.0.0)\n",
            "Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "Successfully installed langchain-core-0.3.21 langchain-openai-0.2.10 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for scrpt_or_style in soup([\"script\", \"style\"]):\n",
        "            scrpt_or_style.decompose()\n",
        "        text = soup.get_text(separator=' ')\n",
        "        #Limpar texto\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        parts = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        text_limpo = '\\n'.join(part for part in parts if part)\n",
        "        return text_limpo\n",
        "    else:\n",
        "        print(f\"Failed to fectch the URL. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "extract_text_from_url('https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "DWISw4s1MmAH",
        "outputId": "5005861f-96ef-4abc-c877-13a5ff65a9c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Azure Open AI in VNet - DEV Community\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by\\nSearch\\nAlgolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nBoost\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nKenichiro Nakamura\\nPosted on\\nOct 12, 2023\\nAzure Open AI in VNet\\n# azure\\n# openai\\n# security\\nGPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\\nEven though the models themselves are the same, there are many differences including:\\ncost\\nfunctionalities\\ntype of models and versions\\ngeo location\\nsecurity\\nsupport\\netc.\\nOne of the most important aspects when we use it in an Enterprise Environment is, of course, security.\\nBy using Azure network security features with Azure Open AI, customers can consume the Open AI service from and within the VNet, therefore no information is flowing in public.\\nSample Deployment\\nAzure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\\nGitHub: openai-enterprise-iac\\nThe key features the bicep uses are:\\nVNet\\nVNet integration for Web App\\nPrivate Endpoint for Azure Open AI\\nPrivate Endpoint for Cognitive Search\\nPrivate DNS Zone\\nBy using these features, all the outbound traffic from the Web App only routed inside the VNet and all the names are resolved into private IP addresses. Open AI and Cognitive Search shut down the public IP address, thus there is not public interface endpoint available anymore.\\nDeploy\\nThe bicep file will deploy following Azure Resources.\\nLet's deploy and confirm how it works. I create a resource group in East US region for my own test.\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd\\nopenai-enterprise-iac\\naz group create\\n-n\\nopenaitest\\n-l\\neastus\\naz deployment group create\\n-g\\nopenaitest\\n-f\\n. \\\\i nfra \\\\m ain.bicep\\nEnter fullscreen mode\\nExit fullscreen mode\\nOnce I run the commend above, I see the deployment started.\\nWait until the deployment completes.\\nTest\\nLet's see if the deployment was succeeded.\\nAzure Open AI\\nLet's try public access first.\\nI could create a deployment without any issue. But when I try from the Chat playground in my Azure Portal, I see the following error.\\nHow about access via the Web API?\\nFrom an advanced tool of the App Service, I login to Bash session, and first I ping the service URL.\\nI see the private IP address assigned to the Private Endpoint is returend.\\nThen I use curl command to send request to the endpoint.\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\n•\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nRead next\\nUnderstanding SSL/TLS: The Role of Encryption and Security Protocols in Internet Communication\\nAryaGG -\\nNov 12\\nI Made an Open Source User Interface for OpenAI APIs\\nRenjith V K -\\nOct 29\\nSkills Required To Become A Machine Learning (ML) Engineer\\nTechDogs -\\nNov 21\\nCREATING AND CONNECTING TO A LINUX VIRTUAL MACHINE SCALE SET\\nSeyi Lufadeju -\\nNov 11\\nKenichiro Nakamura\\nFollow\\nJoined\\nFeb 3, 2018\\nMore from\\nKenichiro Nakamura\\nAzure ML Prompt flow: Use content safety before sending a request to LLM\\n# azure\\n# promptflow\\n# contentsafety\\nDon't waste time to write README, use readme-ai instead\\n# ai\\n# readme\\n# openai\\nC#: Azure Open AI and Function Calling\\n# azure\\n# openai\\n# functioncalling\\nThank you to our Diamond Sponsor\\nNeon\\nfor supporting our community.\\nDEV Community\\n— A constructive and inclusive social network for software developers. With you every step of your journey.\\nHome\\nDEV++\\nPodcasts\\nVideos\\nTags\\nDEV Help\\nForem Shop\\nAdvertise on DEV\\nDEV Challenges\\nDEV Showcase\\nAbout\\nContact\\nFree Postgres Database\\nGuides\\nSoftware comparisons\\nCode of Conduct\\nPrivacy Policy\\nTerms of use\\nBuilt on\\nForem\\n— the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\n©\\n2016 - 2024.\\nWe're a place where coders share, stay up-to-date and grow their careers.\\nLog in\\nCreate account\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "    azure_endpoint = \"https://oai-dio-bootcamp-dev-eastus-001.openai.azure.com/\",\n",
        "    api_key = \"730f2276a6a54c01964cf11672f08e7c\",\n",
        "    api_version = \"2024-02-15-preview8\",\n",
        "    deployment_name = \"gpt-4o-mini\",\n",
        "    max_retries = 0\n",
        ")\n",
        "\n",
        "def translate_article(text, lang):\n",
        "    messages = [\n",
        "        (\"system\" , \"Você atua como tradutor de textos\")\n",
        "        (\"user\", f\"Traduza o {text} para o idioma {lang} e responda em markdown\")\n",
        "    ]\n",
        "\n",
        "    response = client.inoke(messages)\n",
        "    print(response.content)\n",
        "    return response.content\n",
        "\n",
        "    translate_article(\"Azure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\", \"portugues\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVTvSwLhNBbc",
        "outputId": "f9082b66-c8eb-4432-e4f2-240b437fc1b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "<>:13: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "<ipython-input-11-41bf859b76ec>:13: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "  (\"system\" , \"Você atua como tradutor de textos\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'\n",
        "text = extract_text_from_url(url)\n",
        "article = translate_article(text, \"pt-br\")\n",
        "print(text)"
      ],
      "metadata": {
        "id": "fVq7JOF8VGCt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}